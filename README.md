# Python Code Helper RAG System

A production-grade Retrieval-Augmented Generation (RAG) system that provides intelligent Python coding assistance by leveraging GitHub repositories and Stack Overflow data.

## ğŸ—ï¸ Architecture Overview

```mermaid
graph TB
    subgraph "Data Sources"
        GH[GitHub Repositories]
        SO[Stack Overflow]
    end
    
    subgraph "Data Ingestion Layer"
        GHC[GitHub Crawler]
        SOC[SO API Client]
        PP[Preprocessing Pipeline]
    end
    
    subgraph "Processing Layer"
        CP[Code Parser]
        CS[Code Segmenter]
        ME[Metadata Extractor]
        QP[Q&A Parser]
    end
    
    subgraph "Storage Layer"
        VDB[(Vector Database)]
        KG[(Knowledge Graph)]
        MC[(Metadata Cache)]
    end
    
    subgraph "Retrieval Layer"
        HS[Hybrid Search]
        RR[Re-ranking]
        CF[Context Fusion]
    end
    
    subgraph "Generation Layer"
        LLM[Language Model]
        PE[Prompt Engineering]
        CG[Code Generation]
    end
    
    subgraph "API Layer"
        REST[REST API]
        WS[WebSocket]
        AUTH[Authentication]
    end
    
    subgraph "Frontend"
        UI[Web Interface]
        VSC[VS Code Extension]
        CLI[CLI Tool]
    end
    
    GH --> GHC
    SO --> SOC
    GHC --> PP
    SOC --> PP
    PP --> CP
    PP --> QP
    CP --> CS
    CP --> ME
    CS --> VDB
    ME --> MC
    QP --> VDB
    VDB --> HS
    MC --> HS
    KG --> HS
    HS --> RR
    RR --> CF
    CF --> LLM
    LLM --> PE
    PE --> CG
    CG --> REST
    REST --> UI
    REST --> VSC
    REST --> CLI
```

## ğŸš€ Features

- **Intelligent Code Search**: Hybrid search combining semantic and keyword-based retrieval
- **Multi-Source Knowledge**: Integrates GitHub repositories and Stack Overflow Q&As
- **Advanced Code Parsing**: AST-based Python code analysis and semantic chunking
- **Production-Ready**: Clean architecture, comprehensive error handling, and monitoring
- **Scalable Design**: Async operations, caching, and horizontal scaling support
- **Real-time Responses**: Streaming API endpoints for better user experience
- **Quality Assurance**: RAGAS evaluation metrics and continuous monitoring

## ğŸ“‹ Implementation Phases

> ğŸ“– **Detailed Documentation**: See [PHASES_COMPLETED.md](./PHASES_COMPLETED.md) for comprehensive technical documentation of completed phases, including architecture details, code examples, and implementation insights.

### âœ… Phase 1: Project Setup & Foundation - **COMPLETED**
- [x] Project structure setup with clean architecture
- [x] Pydantic-based configuration management with validation
- [x] Structured logging with contextual information
- [x] Comprehensive testing framework with coverage
- [x] Async utilities and text processing tools
- [x] Development environment with quality tools

### âœ… Phase 2: Data Ingestion Infrastructure - **COMPLETED**
- [x] Abstract base collector framework for extensibility
- [x] GitHub repository crawler with intelligent filtering
- [x] Stack Overflow Q&A collector with API integration
- [x] Async data pipeline with concurrent processing
- [x] Comprehensive error handling and retry logic
- [x] Health monitoring and performance metrics

**Key Achievements:**
- **Production-ready collectors** with rate limiting and error recovery
- **26 unit tests** with 44% overall coverage (85%+ for core components)
- **Async pipeline orchestrator** supporting concurrent data collection
- **Rich metadata extraction** for code analysis and Q&A processing
- **Clean architecture** following SOLID principles and best practices

### Phase 3: Data Processing & Chunking (Week 5-6)
- [ ] Advanced Python code parser
- [ ] Semantic chunking strategy
- [ ] Metadata extraction
- [ ] Content preprocessing pipeline

### Phase 4: Vector Storage & Indexing (Week 7-8)
- [ ] Pinecone vector database setup
- [ ] Embedding generation pipeline
- [ ] Hybrid search implementation
- [ ] Search result ranking

### Phase 5: Generation & LLM Integration (Week 9-10)
- [ ] OpenAI API integration
- [ ] Advanced prompt engineering
- [ ] Streaming response generation
- [ ] Context management

### Phase 6: API Layer & Services (Week 11-12)
- [ ] FastAPI application
- [ ] REST and WebSocket endpoints
- [ ] Authentication and rate limiting
- [ ] Background task processing

### Phase 7: Evaluation & Monitoring (Week 13-14)
- [ ] RAGAS evaluation implementation
- [ ] Prometheus metrics collection
- [ ] Performance monitoring dashboard
- [ ] A/B testing framework

### Phase 8: Frontend Development (Week 15-16)
- [ ] React web interface
- [ ] VS Code extension (optional)
- [ ] CLI tool
- [ ] User feedback system

### Phase 9: Deployment & DevOps (Week 17-18)
- [ ] Docker containerization
- [ ] Kubernetes deployment
- [ ] CI/CD pipeline
- [ ] Production monitoring

## ğŸ› ï¸ Technology Stack

### Core Technologies
- **Backend**: Python 3.11+, FastAPI, Uvicorn
- **Vector Database**: Pinecone
- **LLM**: OpenAI GPT-4 Turbo
- **Embeddings**: Sentence Transformers (all-MiniLM-L6-v2)
- **Search**: Hybrid (semantic + BM25)

### Data Sources
- **GitHub API**: Repository code extraction
- **Stack Overflow API**: Q&A data collection
- **AST Parser**: Python code analysis

### Infrastructure
- **Containerization**: Docker, Docker Compose
- **Orchestration**: Kubernetes
- **Monitoring**: Prometheus, Grafana
- **Caching**: Redis
- **CI/CD**: GitHub Actions

### Frontend
- **Web UI**: React, TypeScript, Material-UI
- **Editor Extension**: VS Code API
- **CLI**: Click, Rich

## ğŸ“ Project Structure

```
python-code-helper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ ingestion/           # Data collection modules
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ github_crawler.py
â”‚   â”‚   â”œâ”€â”€ stackoverflow_collector.py
â”‚   â”‚   â””â”€â”€ base_collector.py
â”‚   â”œâ”€â”€ processing/          # Data processing pipeline
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ code_parser.py
â”‚   â”‚   â”œâ”€â”€ chunker.py
â”‚   â”‚   â””â”€â”€ metadata_extractor.py
â”‚   â”œâ”€â”€ storage/            # Vector database operations
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”‚   â””â”€â”€ cache_manager.py
â”‚   â”œâ”€â”€ retrieval/          # Search and retrieval
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ hybrid_search.py
â”‚   â”‚   â””â”€â”€ reranker.py
â”‚   â”œâ”€â”€ generation/         # LLM integration
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ code_generator.py
â”‚   â”‚   â”œâ”€â”€ prompt_templates.py
â”‚   â”‚   â””â”€â”€ response_formatter.py
â”‚   â”œâ”€â”€ api/               # FastAPI application
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ endpoints/
â”‚   â”‚   â””â”€â”€ middleware/
â”‚   â”œâ”€â”€ evaluation/        # Testing and metrics
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ rag_evaluator.py
â”‚   â”‚   â””â”€â”€ test_cases.py
â”‚   â”œâ”€â”€ monitoring/        # Metrics and logging
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ metrics_collector.py
â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ config/           # Configuration management
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â””â”€â”€ utils/            # Utility functions
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ async_utils.py
â”‚       â””â”€â”€ text_utils.py
â”œâ”€â”€ tests/                # Test suite
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ e2e/
â”œâ”€â”€ frontend/             # Web interface
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ public/
â”‚   â””â”€â”€ package.json
â”œâ”€â”€ scripts/              # Deployment and utility scripts
â”‚   â”œâ”€â”€ setup.sh
â”‚   â”œâ”€â”€ deploy.sh
â”‚   â””â”€â”€ data_migration.py
â”œâ”€â”€ docker/              # Docker configurations
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ docker-compose.yml
â”‚   â””â”€â”€ docker-compose.prod.yml
â”œâ”€â”€ k8s/                 # Kubernetes manifests
â”‚   â”œâ”€â”€ deployment.yaml
â”‚   â”œâ”€â”€ service.yaml
â”‚   â””â”€â”€ ingress.yaml
â”œâ”€â”€ monitoring/          # Monitoring configs
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/
â”œâ”€â”€ docs/               # Documentation
â”‚   â”œâ”€â”€ api.md
â”‚   â”œâ”€â”€ deployment.md
â”‚   â””â”€â”€ contributing.md
â”œâ”€â”€ .github/            # GitHub Actions
â”‚   â””â”€â”€ workflows/
â”œâ”€â”€ requirements.txt    # Python dependencies
â”œâ”€â”€ pyproject.toml     # Project configuration
â”œâ”€â”€ .env.template      # Environment variables template
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸš€ Quick Start

### Prerequisites

- Python 3.11+
- Node.js 18+ (for frontend)
- Docker and Docker Compose
- Git

### Environment Setup

1. **Clone the repository**
```bash
git clone https://github.com/your-org/python-code-helper.git
cd python-code-helper
```

2. **Create virtual environment**
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
cp .env.template .env
# Edit .env with your API keys and configuration
```

5. **Run the application**
```bash
# Development mode
uvicorn src.api.main:app --reload --host 0.0.0.0 --port 8000

# Or using Docker Compose
docker-compose up -d
```

### Required Environment Variables

```bash
# API Keys
OPENAI_API_KEY=your_openai_api_key
GITHUB_TOKEN=your_github_token
PINECONE_API_KEY=your_pinecone_api_key
STACKOVERFLOW_API_KEY=your_so_api_key  # Optional

# Database Configuration
PINECONE_ENVIRONMENT=us-east-1-aws
PINECONE_INDEX_NAME=python-code-helper

# Model Configuration
EMBEDDING_MODEL=all-MiniLM-L6-v2
LLM_MODEL=gpt-4-turbo-preview

# Processing Configuration
CHUNK_SIZE=1000
CHUNK_OVERLAP=200
MAX_TOKENS=4000

# Server Configuration
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO
```

## ğŸ“– API Documentation

### Main Endpoints

#### Query Code Helper
```http
POST /api/query
Content-Type: application/json

{
  "query": "How do I implement a binary search tree in Python?",
  "response_type": "code_explanation",
  "max_results": 10,
  "include_sources": true
}
```

#### Streaming Response
```http
POST /api/query/stream
Content-Type: application/json

{
  "query": "Explain Python decorators with examples",
  "response_type": "code_explanation"
}
```

#### Start Data Indexing
```http
POST /api/index
Content-Type: application/json

{
  "repositories": ["python/cpython", "django/django"],
  "stackoverflow_tags": ["python", "django"],
  "max_repos": 50,
  "max_so_posts": 1000
}
```

## ğŸ§ª Testing

### Run Tests
```bash
# Unit tests
pytest tests/unit/ -v

# Integration tests
pytest tests/integration/ -v

# End-to-end tests
pytest tests/e2e/ -v

# All tests with coverage
pytest --cov=src --cov-report=html
```

### Evaluation Metrics
```bash
# Run RAGAS evaluation
python scripts/evaluate_rag.py --test-file tests/evaluation_dataset.json

# Performance benchmarks
python scripts/benchmark.py --queries 100 --concurrent-users 10
```

## ğŸ“Š Monitoring

### Metrics Dashboard
- **Prometheus**: `http://localhost:9090`
- **Grafana**: `http://localhost:3001` (admin/admin)

### Key Metrics
- Query response time
- Confidence scores
- User feedback ratings
- Search accuracy
- System resource usage

## ğŸ³ Deployment

### Docker Deployment
```bash
# Build and run
docker-compose up -d

# Scale services
docker-compose up -d --scale api=3
```

### Kubernetes Deployment
```bash
# Apply manifests
kubectl apply -f k8s/

# Check deployment
kubectl get pods -l app=python-code-helper
```

### Production Considerations
- Use managed vector databases (Pinecone Pro)
- Implement proper load balancing
- Set up SSL/TLS certificates
- Configure backup and disaster recovery
- Monitor resource usage and costs

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

### Development Guidelines
- Follow PEP 8 style guidelines
- Add comprehensive type hints
- Write unit tests for new features
- Update documentation as needed
- Use conventional commit messages

## ğŸ“ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- OpenAI for GPT-4 API
- Pinecone for vector database
- LangChain community for RAG patterns
- GitHub and Stack Overflow for data sources

## ğŸ“ Support

- **Documentation**: [docs/](docs/)
- **Issues**: [GitHub Issues](https://github.com/your-org/python-code-helper/issues)
- **Discussions**: [GitHub Discussions](https://github.com/your-org/python-code-helper/discussions)

---

**Built with â¤ï¸ by the Python Code Helper Team** 